{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W4PmShw9dIt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dVs3XBFDRb3",
        "outputId": "081b2006-6858-42e4-f18f-544c5afad8c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download stopwords for removing common words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Download punkt for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download wordnet for lemmatization\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Download averaged_perceptron_tagger for POS tagging (used in some preprocessing)\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7m0iS7iDRQK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5VB2AuM9d3U",
        "outputId": "99eb193a-b545-4874-e740-dd318310565a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'statement', 'status'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from csv import QUOTE_NONE\n",
        "\n",
        "data = pd.read_csv('/content/Combined Data.csv', on_bad_lines='skip', quoting=QUOTE_NONE)\n",
        "print(data.columns)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw82qu9tW-mg",
        "outputId": "43f5e556-4495-4393-8ac0-ebbb83b610e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHmNLnTqW9Eg",
        "outputId": "402a213a-b5a8-41ed-af18-dd4d0b61740f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJGWHmVFJcyn",
        "outputId": "fb1a5ca9-ab85-465f-9ab2-16892be29e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/Combined Data.csv')\n",
        "\n",
        "# Clean and preprocess data\n",
        "data = data.dropna(subset=['statement', 'status'])  # Remove rows with missing values\n",
        "data['statement'] = data['statement'].astype(str)  # Ensure all statements are strings\n",
        "data['status'] = data['status'].str.strip()  # Remove leading/trailing spaces\n",
        "data['status'] = data['status'].str.replace('Bipolar', 'Bi-Polar')  # Standardize label variations\n",
        "\n",
        "# Encode labels using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(data['status'])\n",
        "y = to_categorical(y)  # One-hot encode the labels\n",
        "\n",
        "# Tokenize and pad text data\n",
        "texts = data['statement'].values\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X = tokenizer.texts_to_sequences(texts)\n",
        "X = pad_sequences(X, padding='post', maxlen=100)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(label_encoder.transform(data['status'])),\n",
        "    y=label_encoder.transform(data['status'])\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
        "    GRU(128, dropout=0.2),\n",
        "    Dense(7, activation='softmax')  # Adjust for number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test_classes, y_pred_classes):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes, target_names=label_encoder.classes_))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
        "\n",
        "# Define prediction function\n",
        "def predict_statement(model, tokenizer, label_encoder, statement, max_len=100):\n",
        "    \"\"\"\n",
        "    Predict the mental health status for a given statement.\n",
        "\n",
        "    Args:\n",
        "        model: Trained GRU model.\n",
        "        tokenizer: Fitted tokenizer for text preprocessing.\n",
        "        label_encoder: Fitted LabelEncoder for decoding class labels.\n",
        "        statement: Input statement (string).\n",
        "        max_len: Maximum length for padding sequences.\n",
        "\n",
        "    Returns:\n",
        "        Predicted class label (string) and confidence score.\n",
        "    \"\"\"\n",
        "    # Preprocess the input statement\n",
        "    sequence = tokenizer.texts_to_sequences([statement])\n",
        "    padded_sequence = pad_sequences(sequence, padding='post', maxlen=max_len)\n",
        "\n",
        "    # Predict using the model\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    confidence_score = np.max(prediction)\n",
        "\n",
        "    # Decode the predicted class\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class_index])[0]\n",
        "\n",
        "    return predicted_label, confidence_score\n",
        "\n",
        "# Example predictions\n",
        "example_statements = [\n",
        "    \"I feel very anxious about tomorrow's presentation.\",\n",
        "    \"I am so tired of everything; I feel like giving up.\",\n",
        "    \"I am happy and content with my current situation.\",\n",
        "    \"Sometimes I get extreme mood swings from happy to sad.\"\n",
        "]\n",
        "\n",
        "# Correct the function call to use predict_statement instead of predict_\n",
        "print(\"\\nMental Health Status Predictions:\\n\")\n",
        "for statement in example_statements:\n",
        "    predicted_label, confidence = predict_statement(model, tokenizer, label_encoder, statement)\n",
        "    print(f\"Statement: {statement}\")\n",
        "    print(f\"Predicted Mental Health Status: {predicted_label} (Confidence: {confidence:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ppAwftXa-At",
        "outputId": "2109c38a-5b0b-44e4-eeee-c683eddff3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 313ms/step - accuracy: 0.4146 - loss: 1.6909 - val_accuracy: 0.6697 - val_loss: 0.8207\n",
            "Epoch 2/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 312ms/step - accuracy: 0.7058 - loss: 0.8867 - val_accuracy: 0.7530 - val_loss: 0.6543\n",
            "Epoch 3/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 309ms/step - accuracy: 0.7780 - loss: 0.5876 - val_accuracy: 0.7598 - val_loss: 0.6377\n",
            "Epoch 4/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 321ms/step - accuracy: 0.8100 - loss: 0.4377 - val_accuracy: 0.7641 - val_loss: 0.6220\n",
            "Epoch 5/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 309ms/step - accuracy: 0.8317 - loss: 0.3451 - val_accuracy: 0.7567 - val_loss: 0.6696\n",
            "Epoch 6/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 333ms/step - accuracy: 0.8492 - loss: 0.2822 - val_accuracy: 0.7579 - val_loss: 0.6930\n",
            "Epoch 7/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 323ms/step - accuracy: 0.8635 - loss: 0.2371 - val_accuracy: 0.7590 - val_loss: 0.7206\n",
            "Epoch 8/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 306ms/step - accuracy: 0.8752 - loss: 0.2078 - val_accuracy: 0.7639 - val_loss: 0.7332\n",
            "Epoch 9/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 326ms/step - accuracy: 0.8852 - loss: 0.1862 - val_accuracy: 0.7623 - val_loss: 0.7705\n",
            "Epoch 10/10\n",
            "\u001b[1m659/659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 326ms/step - accuracy: 0.8981 - loss: 0.1604 - val_accuracy: 0.7640 - val_loss: 0.7867\n",
            "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 35ms/step\n",
            "Accuracy: 0.7640\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "             Anxiety       0.74      0.81      0.77       755\n",
            "            Bi-Polar       0.65      0.77      0.71       527\n",
            "          Depression       0.77      0.64      0.70      3016\n",
            "              Normal       0.93      0.91      0.92      3308\n",
            "Personality disorder       0.52      0.68      0.59       237\n",
            "              Stress       0.59      0.60      0.59       536\n",
            "            Suicidal       0.65      0.75      0.70      2158\n",
            "\n",
            "            accuracy                           0.76     10537\n",
            "           macro avg       0.69      0.74      0.71     10537\n",
            "        weighted avg       0.77      0.76      0.77     10537\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 608   45   15   23   16   43    5]\n",
            " [  25  408   26    8   32   22    6]\n",
            " [  56   79 1921   75   48   52  785]\n",
            " [  46   28   47 3003   24   80   80]\n",
            " [  17   18   16    7  160   13    6]\n",
            " [  60   32   45   46   26  321    6]\n",
            " [   9   13  435   53    4   15 1629]]\n",
            "\n",
            "Mental Health Status Predictions:\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Statement: I feel very anxious about tomorrow's presentation.\n",
            "Predicted Mental Health Status: Anxiety (Confidence: 1.00)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Statement: I am so tired of everything; I feel like giving up.\n",
            "Predicted Mental Health Status: Depression (Confidence: 0.51)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Statement: I am happy and content with my current situation.\n",
            "Predicted Mental Health Status: Normal (Confidence: 0.88)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Statement: Sometimes I get extreme mood swings from happy to sad.\n",
            "Predicted Mental Health Status: Depression (Confidence: 0.88)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HeBRHx55X0Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Accuracy results for the models\n",
        "logistic_regression_accuracies = np.array([78, 77, 78, 77])  # Logistic Regression model\n",
        "gru_accuracies = np.array([76.1, 77.0, 76.0, 76.0])  # GRU model\n",
        "\n",
        "# Calculate the differences between the two models\n",
        "differences = logistic_regression_accuracies - gru_accuracies\n",
        "\n",
        "# Perform the paired t-test\n",
        "t_statistic, p_value = stats.ttest_1samp(differences, 0)\n",
        "\n",
        "# Output the results\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpreting the result\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the models.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the models.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chDNksr1XLCf",
        "outputId": "619d8078-308f-4695-bffe-def6ea991c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: 2.627934601251784\n",
            "P-value: 0.07846422716984412\n",
            "Fail to reject the null hypothesis: There is no significant difference between the models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Accuracy results for the models\n",
        "logistic_regression_accuracies = np.array([78, 77, 78, 77])  # Logistic Regression model\n",
        "lstm_accuracies = np.array([74.9, 75, 75, 75])  # LSTM model\n",
        "\n",
        "# Calculate the differences between the two models\n",
        "differences = logistic_regression_accuracies - lstm_accuracies\n",
        "\n",
        "# Perform the paired t-test\n",
        "t_statistic, p_value = stats.ttest_1samp(differences, 0)\n",
        "\n",
        "# Output the results\n",
        "print(f\"T-statistic: {t_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpreting the result\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the models.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the models.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0BYHcqeYZ3H",
        "outputId": "761e3c0f-a907-4da9-b12c-93b76b797e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: 8.311513948033323\n",
            "P-value: 0.003649630156265394\n",
            "Reject the null hypothesis: There is a significant difference between the models.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}