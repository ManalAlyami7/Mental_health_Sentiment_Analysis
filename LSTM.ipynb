{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f82mQYLtx3f",
        "outputId": "95dd2c6e-9eed-4300-949f-953bfca9f8a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names: Index(['Unnamed: 0', 'statement', 'status'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/Combined Data.csv\")\n",
        "\n",
        "# Display column names\n",
        "print(\"Column names:\", data.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRsTcvDUwhQw",
        "outputId": "0c65ef13-411a-4ff7-8985-580e4c5b1915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6arES7qbwsCT"
      },
      "outputs": [],
      "source": [
        "# Map mental health status labels to numeric values\n",
        "label_mapping = {'Normal': 0, 'Depression': 1, 'Suicidal': 2, 'Anxiety': 3, 'Stress': 4, 'Bipolar': 5, 'Personality disorder': 6}\n",
        "data['status'] = data['status'].map(label_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rkT5bc-wtPJ"
      },
      "outputs": [],
      "source": [
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = re.sub(r'\\d+', '', text)      # Remove digits\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]  # Lemmatization\n",
        "    return ' '.join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpIXV-XjwwzS"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Apply text cleaning\n",
        "data['statement'] = data['statement'].fillna('').astype(str).apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for modeling\n",
        "texts = data['statement'].values\n",
        "labels = data['status'].values"
      ],
      "metadata": {
        "id": "HoCP78rX3rDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenization and padding\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "word_index = tokenizer.word_index\n",
        "max_len = 100\n",
        "data_padded = pad_sequences(sequences, maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "oQi_DwpO3ui9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_padded, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WX1hc8yY3zkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build Bidirectional LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=128, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation='softmax'))  # 7 classes for each mental health status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeD3BlUG4cD9",
        "outputId": "a09a7e96-8c46-44cf-e6e8-0e6d8cc9bf6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "WtntvVEm4nEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07kX-pru4qnK",
        "outputId": "f9aaa173-8b11-40c3-806e-1771315b2505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m531/531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 543ms/step - accuracy: 0.5232 - loss: 1.2355 - val_accuracy: 0.6766 - val_loss: 0.8259\n",
            "Epoch 2/5\n",
            "\u001b[1m531/531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 554ms/step - accuracy: 0.7191 - loss: 0.7495 - val_accuracy: 0.7295 - val_loss: 0.7129\n",
            "Epoch 3/5\n",
            "\u001b[1m531/531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 528ms/step - accuracy: 0.7931 - loss: 0.5906 - val_accuracy: 0.7342 - val_loss: 0.7184\n",
            "Epoch 4/5\n",
            "\u001b[1m531/531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 529ms/step - accuracy: 0.8217 - loss: 0.5035 - val_accuracy: 0.7403 - val_loss: 0.7236\n",
            "Epoch 5/5\n",
            "\u001b[1m531/531\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 526ms/step - accuracy: 0.8589 - loss: 0.4091 - val_accuracy: 0.7315 - val_loss: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predictions and evaluation metrics\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y2vZB3g-4O9",
        "outputId": "385759d3-b42c-4722-f049-c774efff4072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_classes)\n",
        "precision = precision_score(y_test, y_pred_classes, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11MVQ5Ht_DsB",
        "outputId": "5d0f0e4e-f976-4792-d935-c602f60cba25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.90%\n",
            "Precision: 0.75\n",
            "Recall: 0.75\n",
            "F1 Score: 0.75\n",
            "Confusion Matrix:\n",
            "[[3017  102   93   34   56   10   15]\n",
            " [  83 2093  785   36   15   42   46]\n",
            " [  77  464 1464    3    5    5    0]\n",
            " [  29   62   11  608   22   38    9]\n",
            " [  75  107   25   67  230   19   34]\n",
            " [  47   51    8   17    7  426   24]\n",
            " [  46   49    9   13    8   15  108]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Replace these with your actual F1-scores from repeated runs\n",
        "lstm_f1_scores = [0.75, 0.74, 0.75, 0.76, 0.75]\n",
        "gru_f1_scores = [0.76, 0.77, 0.76, 0.76, 0.77]\n",
        "\n",
        "# Perform T-test\n",
        "t_stat, p_value = ttest_ind(gru_f1_scores, lstm_f1_scores)\n",
        "\n",
        "# Display the results\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"The GRU model's performance is significantly better than the LSTM model.\")\n",
        "else:\n",
        "    print(\"There is no significant difference between the GRU and LSTM models.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS_HDok--Xah",
        "outputId": "f130c95f-b7ec-4023-e8b2-1b74b1bd6517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T-statistic: 3.5\n",
            "P-value: 0.00807908226041189\n",
            "The GRU model's performance is significantly better than the LSTM model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example: Assuming `model` is your trained GRU or LSTM model and `X_test` is the test dataset.\n",
        "\n",
        "# Simulating a mock test dataset and predictions for demonstration purposes\n",
        "# Replace with your actual test dataset (X_test) and true labels (y_test)\n",
        "mock_test_data = [\n",
        "    \"I feel really good today!\",\n",
        "    \"I'm feeling very anxious about tomorrow.\",\n",
        "    \"I don't know how to continue with life.\",\n",
        "    \"I'm managing, but things are hard.\",\n",
        "    \"I have a lot of energy and feel unstoppable!\"\n",
        "]\n",
        "\n",
        "# Mock predictions (Replace with actual predictions from your model)\n",
        "mock_true_labels = [\"Normal\", \"Anxiety\", \"Suicidal\", \"Stress\", \"Bipolar\"]\n",
        "mock_predicted_labels = [\"Normal\", \"Anxiety\", \"Suicidal\", \"Stress\", \"Normal\"]\n",
        "\n",
        "# Combine test data with predictions for display\n",
        "predictions_output = list(zip(mock_test_data, mock_true_labels, mock_predicted_labels))\n",
        "predictions_output\n"
      ],
      "metadata": {
        "id": "vHJc1khtANgR",
        "outputId": "719a537f-ab90-44ce-e141-716a8124831d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I feel really good today!', 'Normal', 'Normal'),\n",
              " (\"I'm feeling very anxious about tomorrow.\", 'Anxiety', 'Anxiety'),\n",
              " (\"I don't know how to continue with life.\", 'Suicidal', 'Suicidal'),\n",
              " (\"I'm managing, but things are hard.\", 'Stress', 'Stress'),\n",
              " ('I have a lot of energy and feel unstoppable!', 'Bipolar', 'Normal')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}